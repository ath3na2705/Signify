# Project Signify
Project Signify is an innovative mobile application designed to translate Korean Sign Language (KSL) and American Sign Language (ASL) into speech and text. The app uses a CNN-AI-based system to recognize hand gestures and facilitates communication between sign language users and non-sign language users.

## Overview
Project Signify aims to:
- Raise awareness of sign language and hearing disabilities.
- Bridge the communication gap between people with and without hearing disabilities.
- Enhance the representation of minority languages, specifically Korean Sign Language (KSL).

## Key Features
- Real-time Sign Language Recognition: Converts KSL and ASL gestures to text or speech.
- AI-Powered Translation: Leverages CNN models to accurately recognize hand gestures.
- Multilingual Support: Facilitates both KSL and ASL.

## Problem Statement
We aim to develop an efficient system to facilitate communication between sign language users and non-sign language users, tackling challenges like:
1. Hand gesture accuracy in different environments.
2. Limited high-quality KSL and ASL datasets.
3. Real-time gesture processing on mobile devices.

## Technologies Used
Mobile Frameworks: React, Flutter, or Xcode
AI/ML Tools: TensorFlow, Keras, PyTorch
Backend: Python Django
Text-to-Speech: gTTS, playsound
Speech-to-Text: SpeechRecognition
